{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1142a00d",
   "metadata": {},
   "source": [
    "## spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f390bc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bb4244",
   "metadata": {},
   "source": [
    "Sentence Tokenization in Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99f64493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple is looking at buying U.K. startup for $1 billion.\n",
      "Apple want to build indutries in india\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion. Apple want to build indutries in india\")\n",
    " \n",
    "for sentence in doc.sents:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7912f216",
   "metadata": {},
   "source": [
    "Word Tokenization in Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5223fbbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple\n",
      "is\n",
      "looking\n",
      "at\n",
      "buying\n",
      "U.K.\n",
      "startup\n",
      "for\n",
      "$\n",
      "1\n",
      "billion\n",
      ".\n",
      "Apple\n",
      "want\n",
      "to\n",
      "build\n",
      "indutries\n",
      "in\n",
      "india\n"
     ]
    }
   ],
   "source": [
    "for sentence in doc.sents:\n",
    "    for word in sentence:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4eb26d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\gadhv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f80101a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Apple is looking at buying U.K. startup for $1 billion.',\n",
       " 'Apple want to build indutries in india']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "sent_tokenize(\"Apple is looking at buying U.K. startup for $1 billion. Apple want to build indutries in india\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ac16606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Apple',\n",
       " 'is',\n",
       " 'looking',\n",
       " 'at',\n",
       " 'buying',\n",
       " 'U.K.',\n",
       " 'startup',\n",
       " 'for',\n",
       " '$',\n",
       " '1',\n",
       " 'billion',\n",
       " '.',\n",
       " 'Apple',\n",
       " 'want',\n",
       " 'to',\n",
       " 'build',\n",
       " 'indutries',\n",
       " 'in',\n",
       " 'india']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "word_tokenize(\"Apple is looking at buying U.K. startup for $1 billion. Apple want to build indutries in india\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a635012",
   "metadata": {},
   "source": [
    "## tokenization in SPACY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd16ce2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a30e8b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple\n",
      "is\n",
      "looking\n",
      "at\n",
      "buying\n",
      "U.K.\n",
      "startup\n",
      "for\n",
      "$\n",
      "1\n",
      "billion\n",
      ".\n",
      "Apple\n",
      "want\n",
      "to\n",
      "build\n",
      "indutries\n",
      "in\n",
      "india\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion. Apple want to build indutries in india\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7efae4d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "\"\n",
      "Let\n",
      "'s\n",
      "go\n",
      "to\n",
      "N.Y.\n",
      "!\n",
      "\"\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(''' \"Let's go to N.Y.!\" ''')\n",
    "\n",
    "for token in doc:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0c48192",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.lang.en.English"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54322fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"tony gave two $ to peter.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86c2885e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tony"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token = doc[0]\n",
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1edc9188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.token.Token"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78cd8fed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token.like_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8df29443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tony  == > index:  0 is_alpha: True is_punct: False like_num: False is_currency: False\n",
      "gave  == > index:  1 is_alpha: True is_punct: False like_num: False is_currency: False\n",
      "two  == > index:  2 is_alpha: True is_punct: False like_num: True is_currency: False\n",
      "$  == > index:  3 is_alpha: False is_punct: False like_num: False is_currency: True\n",
      "to  == > index:  4 is_alpha: True is_punct: False like_num: False is_currency: False\n",
      "peter  == > index:  5 is_alpha: True is_punct: False like_num: False is_currency: False\n",
      ".  == > index:  6 is_alpha: False is_punct: True like_num: False is_currency: False\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token, \" == >\", \"index: \", token.i, \"is_alpha:\", token. is_alpha,\n",
    "\"is_punct:\", token. is_punct,\n",
    "\"like_num:\", token.like_num,\n",
    "\"is_currency:\", token.is_currency,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eb067919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Name\\n',\n",
       " '\\n',\n",
       " 'Virat\\n',\n",
       " '7 Maria\\n',\n",
       " 'Serena\\n',\n",
       " '9 Joe\\n',\n",
       " '\\n',\n",
       " 'Dayton high school, 8th grade students information\\n',\n",
       " '\\n',\n",
       " 'birth day\\n',\n",
       " '\\n',\n",
       " '5 June, 1882\\n',\n",
       " '12 April, 2001\\n',\n",
       " '24 June, 1998\\n',\n",
       " '1 May, 1997\\n',\n",
       " '\\n',\n",
       " 'email\\n',\n",
       " '\\n',\n",
       " 'virat@kohli.com\\n',\n",
       " 'maria@sharapova.com\\n',\n",
       " 'serena@williams.com\\n',\n",
       " 'joe@root.com']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"student.txt\") as f:\n",
    "    text = f.readlines()\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dba33f29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Name\\n \\n Virat\\n 7 Maria\\n Serena\\n 9 Joe\\n \\n Dayton high school, 8th grade students information\\n \\n birth day\\n \\n 5 June, 1882\\n 12 April, 2001\\n 24 June, 1998\\n 1 May, 1997\\n \\n email\\n \\n virat@kohli.com\\n maria@sharapova.com\\n serena@williams.com\\n joe@root.com'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \" \".join(text)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9d1456a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['virat@kohli.com',\n",
       " 'maria@sharapova.com',\n",
       " 'serena@williams.com',\n",
       " 'joe@root.com']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(text)\n",
    "\n",
    "emails = []\n",
    "for token in doc:\n",
    "    if token.like_email:\n",
    "        emails.append(token.text)\n",
    "emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "414d0dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "कैसे\n",
      "हो\n",
      "भे\n",
      ",\n",
      "मेरे\n",
      "को\n",
      "निन्द\n",
      "आ\n",
      "रहि\n",
      "है\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.blank(\"hi\")\n",
    "\n",
    "\n",
    "doc = nlp(\"कैसे हो भे, मेरे को निन्द आ रहि है\")\n",
    "for token in doc:\n",
    "    print(token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "673deb27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gimme', 'double', 'cheese', 'extra', 'large', 'burger', 'with', 'coke']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp (\"gimme double cheese extra large burger with coke\")\n",
    "\n",
    "tokens = [token.text for token in doc]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4e04f06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.pipeline.sentencizer.Sentencizer at 0x16c48915310>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.add_pipe(\"sentencizer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b283d95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sentencizer']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed1ec632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gimme.\n",
      "double cheese extra large burger with coke\n"
     ]
    }
   ],
   "source": [
    "doc = nlp (\"gimme. double cheese extra large burger with coke\")\n",
    "\n",
    "for sentence in doc.sents:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e197bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
