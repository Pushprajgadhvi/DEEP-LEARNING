{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "550b1078",
   "metadata": {},
   "source": [
    "!!next word predictor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aa2d7582",
   "metadata": {},
   "outputs": [],
   "source": [
    "faqs = \"\"\"\n",
    "What is the Data Science Mentorship Program?\n",
    "The Data Science Mentorship Program is a 7-month structured program with live classes and assignments.\n",
    "\n",
    "What is the course fee?\n",
    "The program follows a monthly subscription of Rs 799 per month.\n",
    "\n",
    "What is the total duration of the course?\n",
    "The total duration is 7 months.\n",
    "\n",
    "What topics are covered in the program?\n",
    "The program covers Python, Data Science Libraries, SQL, Data Analysis, Machine Learning, MLOps, Case Studies, and Maths for ML.\n",
    "\n",
    "Will Deep Learning be covered?\n",
    "No, Deep Learning is not included in this program.\n",
    "\n",
    "Will NLP be covered?\n",
    "No, NLP is also not included.\n",
    "\n",
    "What if I miss a live session?\n",
    "All sessions are recorded. You will get access to the recording if you miss a class.\n",
    "\n",
    "Where can I find the class schedule?\n",
    "The class schedule is updated monthly on the dashboard.\n",
    "\n",
    "What is the duration of each session?\n",
    "Most live sessions are around 2 hours long.\n",
    "\n",
    "Which language will be used during the sessions?\n",
    "The instructor teaches in Hinglish.\n",
    "\n",
    "How will I be informed about upcoming sessions?\n",
    "You will receive email notifications for every paid session.\n",
    "\n",
    "Can a non-technical student join this program?\n",
    "Yes, absolutely. The course is designed for beginners.\n",
    "\n",
    "Can I join the program late?\n",
    "Yes, you can join anytime during the year.\n",
    "\n",
    "Will I get access to past lectures if I join late?\n",
    "Yes, once you make the payment, all previous recordings will be unlocked.\n",
    "\n",
    "Do we need to submit tasks?\n",
    "You do not need to submit tasks. Solutions will be provided for self-evaluation.\n",
    "\n",
    "Will there be case studies?\n",
    "Yes, multiple real-world case studies are included.\n",
    "\n",
    "How can I contact support?\n",
    "You can email us at support@campusx.com.\n",
    "\n",
    "Where should I make the payment?\n",
    "Payments must be made on our official website.\n",
    "\n",
    "Can I pay the full amount at once?\n",
    "No, the program follows only a monthly subscription model.\n",
    "\n",
    "What is the validity of the monthly subscription?\n",
    "Your subscription is valid for 30 days from the date of payment.\n",
    "\n",
    "What is the refund policy?\n",
    "You get a 7-day refund period from the date of payment.\n",
    "\n",
    "What if I live outside India and my payment fails?\n",
    "You can email the support team for international payment assistance.\n",
    "\n",
    "Till when can I watch the videos?\n",
    "You can watch videos as long as your subscription is active. After completing all payments, full content becomes unlocked.\n",
    "\n",
    "Why isn’t lifetime access provided?\n",
    "Lifetime access is not provided due to the low course fees.\n",
    "\n",
    "How can I get doubt-clearing support?\n",
    "Fill out the doubt form and the team will schedule a 1-on-1 doubt session.\n",
    "\n",
    "If I join late, can I ask doubts from previous weeks?\n",
    "Yes, you can select \"Past Week Doubt\" in the doubt form.\n",
    "\n",
    "What is the certificate criteria?\n",
    "You must complete all assignments and pay the full 7-month subscription.\n",
    "\n",
    "Is placement assistance included?\n",
    "Placement assistance includes portfolio review, resume building, interview guidance, and job-search strategies. It does not guarantee a job.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d668c141",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "09f8b09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6e3f4e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts([faqs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b9ca2d89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "208"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "93701250",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences = []\n",
    "for sentence in faqs.split('\\n'):\n",
    "    tokenize_sentence = tokenizer.texts_to_sequences([sentence])[0]\n",
    "\n",
    "for i in range(1, len(tokenize_sentence)):\n",
    "    input_sequences.append(tokenize_sentence[: i+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "051bdae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4b1e944f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rebuild input_sequences correctly and compute max_len with a safe fallback\n",
    "input_sequences = []\n",
    "for sentence in faqs.split('\\n'):\n",
    "    tokenize_sentence = tokenizer.texts_to_sequences([sentence])[0]\n",
    "    if not tokenize_sentence:\n",
    "        continue\n",
    "    for i in range(1, len(tokenize_sentence) + 1):\n",
    "        input_sequences.append(tokenize_sentence[:i])\n",
    "\n",
    "# compute max_len (fallback to padded_input_sequences if input_sequences is empty)\n",
    "if input_sequences:\n",
    "    max_len = max(len(x) for x in input_sequences)\n",
    "else:\n",
    "    max_len = padded_input_sequences.shape[1] if 'padded_input_sequences' in globals() else 0\n",
    "\n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "765b6bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "padded_input_sequences = pad_sequences(input_sequences , maxlen = max_len , padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "16b48700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0, ...,   0,   0,   7],\n",
       "       [  0,   0,   0, ...,   0,   7,   2],\n",
       "       [  0,   0,   0, ...,   7,   2,   1],\n",
       "       ...,\n",
       "       [  0,   0,  88, ..., 207,  16, 208],\n",
       "       [  0,  88,  53, ...,  16, 208,   9],\n",
       "       [ 88,  53, 197, ..., 208,   9,  89]], shape=(501, 19), dtype=int32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_input_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9d0b0dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = padded_input_sequences[: ,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a97dddd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = padded_input_sequences[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cf1829ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(501, 18)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8faea8ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(501,)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "51bf5d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "num_classes = int(Y.max()) + 1\n",
    "y = to_categorical(Y, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7f477a36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(501, 209)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "51a0c418",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding , LSTM , Dense         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ab35047f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(274, 100, input_length = 56))\n",
    "model.add(LSTM(150))\n",
    "model.add(Dense(274, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "40909cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1fd6ae55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_4 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "434e48da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_7\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_7\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_6 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_6 (\u001b[38;5;33mLSTM\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.0479 - loss: 5.3051\n",
      "Epoch 2/30\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.0719 - loss: 5.0234\n",
      "Epoch 3/30\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0739 - loss: 4.8916\n",
      "Epoch 4/30\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0739 - loss: 4.8052\n",
      "Epoch 5/30\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0758 - loss: 4.7349\n",
      "Epoch 6/30\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0778 - loss: 4.6503\n",
      "Epoch 7/30\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0878 - loss: 4.5613\n",
      "Epoch 8/30\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.1058 - loss: 4.4680\n",
      "Epoch 9/30\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.1078 - loss: 4.3819\n",
      "Epoch 10/30\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.1238 - loss: 4.2775\n",
      "Epoch 11/30\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.1297 - loss: 4.1640\n",
      "Epoch 12/30\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.1417 - loss: 4.0542\n",
      "Epoch 13/30\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.1577 - loss: 3.9293\n",
      "Epoch 14/30\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.1537 - loss: 3.8046\n",
      "Epoch 15/30\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.1876 - loss: 3.6550\n",
      "Epoch 16/30\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.1936 - loss: 3.5055\n",
      "Epoch 17/30\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.2196 - loss: 3.3500\n",
      "Epoch 18/30\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.2415 - loss: 3.1997\n",
      "Epoch 19/30\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.2954 - loss: 3.0481\n",
      "Epoch 20/30\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3114 - loss: 2.9087\n",
      "Epoch 21/30\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.3453 - loss: 2.7691\n",
      "Epoch 22/30\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3713 - loss: 2.6403\n",
      "Epoch 23/30\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3972 - loss: 2.5186\n",
      "Epoch 24/30\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4212 - loss: 2.3977\n",
      "Epoch 25/30\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4671 - loss: 2.2733\n",
      "Epoch 26/30\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4930 - loss: 2.1657\n",
      "Epoch 27/30\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5529 - loss: 2.0591\n",
      "Epoch 28/30\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5788 - loss: 1.9536\n",
      "Epoch 29/30\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6128 - loss: 1.8606\n",
      "Epoch 30/30\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6208 - loss: 1.7787\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1b2e1516520>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rebuild model to match your data shapes and use one-hot targets `y`\n",
    "vocab_size = num_classes\n",
    "seq_len = X.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 100, input_length=seq_len))\n",
    "model.add(LSTM(150))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# fit with the one-hot encoded targets\n",
    "model.fit(X, y, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "95d5a5fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 7]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n",
      "what is\n",
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 7 2]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "what is the\n",
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 7 2 1]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "what is the duration\n",
      "[[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  7  2  1 38]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step\n",
      "what is the duration of\n",
      "[[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  7  2  1 38 13]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
      "what is the duration of the\n",
      "[[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  7  2  1 38 13  1]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
      "what is the duration of the program\n",
      "[[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  7  2  1 38 13  1  8]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "what is the duration of the program of\n",
      "[[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   7  2  1 38 13  1  8 13]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "what is the duration of the program of of\n",
      "[[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  7\n",
      "   2  1 38 13  1  8 13 13]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "what is the duration of the program of of the\n",
      "[[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  7  2\n",
      "   1 38 13  1  8 13 13  1]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step\n",
      "what is the duration of the program of of the course\n"
     ]
    }
   ],
   "source": [
    "text = \"what\"\n",
    "\n",
    "for i in range(10):\n",
    "    #tokenize\n",
    " token_text = tokenizer.texts_to_sequences([text])[0]\n",
    "  #padding\n",
    " padded_token_text = pad_sequences([token_text], maxlen=56, padding='pre')\n",
    " print(padded_token_text)\n",
    "\n",
    "#predict\n",
    " pos = np.argmax(model.predict(padded_token_text))\n",
    "\n",
    " for word, index in tokenizer.word_index.items():\n",
    "    if index == pos:\n",
    "        text = text + \" \" + word\n",
    "        print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8606e4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4b02c42a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 1,\n",
       " 'is': 2,\n",
       " 'i': 3,\n",
       " 'can': 4,\n",
       " 'you': 5,\n",
       " 'will': 6,\n",
       " 'what': 7,\n",
       " 'program': 8,\n",
       " 'a': 9,\n",
       " 'be': 10,\n",
       " 'and': 11,\n",
       " 'subscription': 12,\n",
       " 'of': 13,\n",
       " 'for': 14,\n",
       " 'payment': 15,\n",
       " 'not': 16,\n",
       " 'if': 17,\n",
       " 'to': 18,\n",
       " 'join': 19,\n",
       " 'yes': 20,\n",
       " 'doubt': 21,\n",
       " 'data': 22,\n",
       " '7': 23,\n",
       " 'live': 24,\n",
       " 'course': 25,\n",
       " 'monthly': 26,\n",
       " 'are': 27,\n",
       " 'in': 28,\n",
       " 'included': 29,\n",
       " 'session': 30,\n",
       " 'all': 31,\n",
       " 'sessions': 32,\n",
       " 'get': 33,\n",
       " 'access': 34,\n",
       " 'support': 35,\n",
       " 'science': 36,\n",
       " 'month': 37,\n",
       " 'duration': 38,\n",
       " 'covered': 39,\n",
       " 'learning': 40,\n",
       " 'case': 41,\n",
       " 'studies': 42,\n",
       " 'no': 43,\n",
       " 'class': 44,\n",
       " 'schedule': 45,\n",
       " 'on': 46,\n",
       " 'how': 47,\n",
       " 'email': 48,\n",
       " 'late': 49,\n",
       " 'provided': 50,\n",
       " 'full': 51,\n",
       " 'from': 52,\n",
       " 'assistance': 53,\n",
       " 'mentorship': 54,\n",
       " 'assignments': 55,\n",
       " 'follows': 56,\n",
       " 'total': 57,\n",
       " 'deep': 58,\n",
       " 'this': 59,\n",
       " 'nlp': 60,\n",
       " 'miss': 61,\n",
       " 'where': 62,\n",
       " 'long': 63,\n",
       " 'during': 64,\n",
       " 'past': 65,\n",
       " 'once': 66,\n",
       " 'make': 67,\n",
       " 'previous': 68,\n",
       " 'unlocked': 69,\n",
       " 'do': 70,\n",
       " 'need': 71,\n",
       " 'submit': 72,\n",
       " 'tasks': 73,\n",
       " 'at': 74,\n",
       " 'payments': 75,\n",
       " 'must': 76,\n",
       " 'pay': 77,\n",
       " 'your': 78,\n",
       " 'date': 79,\n",
       " 'refund': 80,\n",
       " 'team': 81,\n",
       " 'watch': 82,\n",
       " 'videos': 83,\n",
       " 'as': 84,\n",
       " 'lifetime': 85,\n",
       " 'form': 86,\n",
       " '1': 87,\n",
       " 'placement': 88,\n",
       " 'job': 89,\n",
       " 'structured': 90,\n",
       " 'with': 91,\n",
       " 'classes': 92,\n",
       " 'fee': 93,\n",
       " 'rs': 94,\n",
       " '799': 95,\n",
       " 'per': 96,\n",
       " 'months': 97,\n",
       " 'topics': 98,\n",
       " 'covers': 99,\n",
       " 'python': 100,\n",
       " 'libraries': 101,\n",
       " 'sql': 102,\n",
       " 'analysis': 103,\n",
       " 'machine': 104,\n",
       " 'mlops': 105,\n",
       " 'maths': 106,\n",
       " 'ml': 107,\n",
       " 'also': 108,\n",
       " 'recorded': 109,\n",
       " 'recording': 110,\n",
       " 'find': 111,\n",
       " 'updated': 112,\n",
       " 'dashboard': 113,\n",
       " 'each': 114,\n",
       " 'most': 115,\n",
       " 'around': 116,\n",
       " '2': 117,\n",
       " 'hours': 118,\n",
       " 'which': 119,\n",
       " 'language': 120,\n",
       " 'used': 121,\n",
       " 'instructor': 122,\n",
       " 'teaches': 123,\n",
       " 'hinglish': 124,\n",
       " 'informed': 125,\n",
       " 'about': 126,\n",
       " 'upcoming': 127,\n",
       " 'receive': 128,\n",
       " 'notifications': 129,\n",
       " 'every': 130,\n",
       " 'paid': 131,\n",
       " 'non': 132,\n",
       " 'technical': 133,\n",
       " 'student': 134,\n",
       " 'absolutely': 135,\n",
       " 'designed': 136,\n",
       " 'beginners': 137,\n",
       " 'anytime': 138,\n",
       " 'year': 139,\n",
       " 'lectures': 140,\n",
       " 'recordings': 141,\n",
       " 'we': 142,\n",
       " 'solutions': 143,\n",
       " 'self': 144,\n",
       " 'evaluation': 145,\n",
       " 'there': 146,\n",
       " 'multiple': 147,\n",
       " 'real': 148,\n",
       " 'world': 149,\n",
       " 'contact': 150,\n",
       " 'us': 151,\n",
       " 'campusx': 152,\n",
       " 'com': 153,\n",
       " 'should': 154,\n",
       " 'made': 155,\n",
       " 'our': 156,\n",
       " 'official': 157,\n",
       " 'website': 158,\n",
       " 'amount': 159,\n",
       " 'only': 160,\n",
       " 'model': 161,\n",
       " 'validity': 162,\n",
       " 'valid': 163,\n",
       " '30': 164,\n",
       " 'days': 165,\n",
       " 'policy': 166,\n",
       " 'day': 167,\n",
       " 'period': 168,\n",
       " 'outside': 169,\n",
       " 'india': 170,\n",
       " 'my': 171,\n",
       " 'fails': 172,\n",
       " 'international': 173,\n",
       " 'till': 174,\n",
       " 'when': 175,\n",
       " 'active': 176,\n",
       " 'after': 177,\n",
       " 'completing': 178,\n",
       " 'content': 179,\n",
       " 'becomes': 180,\n",
       " 'why': 181,\n",
       " 'isn’t': 182,\n",
       " 'due': 183,\n",
       " 'low': 184,\n",
       " 'fees': 185,\n",
       " 'clearing': 186,\n",
       " 'fill': 187,\n",
       " 'out': 188,\n",
       " 'ask': 189,\n",
       " 'doubts': 190,\n",
       " 'weeks': 191,\n",
       " 'select': 192,\n",
       " 'week': 193,\n",
       " 'certificate': 194,\n",
       " 'criteria': 195,\n",
       " 'complete': 196,\n",
       " 'includes': 197,\n",
       " 'portfolio': 198,\n",
       " 'review': 199,\n",
       " 'resume': 200,\n",
       " 'building': 201,\n",
       " 'interview': 202,\n",
       " 'guidance': 203,\n",
       " 'search': 204,\n",
       " 'strategies': 205,\n",
       " 'it': 206,\n",
       " 'does': 207,\n",
       " 'guarantee': 208}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226e01ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
